{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn\n",
    "import time\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "text_train,label_train,text_test,label_test = utils.load_raw_data_new()\n",
    "train_len = len(text_train)\n",
    "text_train.extend(text_test)\n",
    "label_train.extend(label_test)\n",
    "text_total = text_train\n",
    "label_total = label_train\n",
    "new_text_total = utils.back_to_doc(text_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en',disable = [\"parser\", \"ner\"])\n",
    "def lemma(doc):\n",
    "    doc = nlp(doc)\n",
    "    lemmatized_doc = ''\n",
    "    for token in doc:\n",
    "        if not token.lemma_ == '-PRON-':\n",
    "            lemmatized_doc += ' ' + token.lemma_\n",
    "    return lemmatized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "lemmatized_text = []\n",
    "for doc in tqdm(new_text_total):\n",
    "    doc = lemma(doc)\n",
    "    lemmatized_text.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_train = lemmatized_text[:train_len]\n",
    "label_train = label_total[:train_len]\n",
    "new_text_test = lemmatized_text[train_len:]\n",
    "label_test = label_total[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _svm_pipeline(global_idf):\n",
    "    Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df =5,stop_words='english',max_df = 0.8)\n",
    "    #--------------------Vectorize----------------------\n",
    "    # Use the idf of whole text or only the idf of training dataset\n",
    "    if global_idf:\n",
    "        Tfidf_vectorizer = Tfidf_vectorizer.fit(new_text_total)\n",
    "    else:\n",
    "        Tfidf_vectorizer = Tfidf_vectorizer.fit(new_text_train)\n",
    "    X_train = Tfidf_vectorizer.transform(new_text_train)\n",
    "    y_train = label_train\n",
    "    X_test = Tfidf_vectorizer.transform(new_text_test)\n",
    "    y_test = label_test\n",
    "    print(np.shape(X_train))\n",
    "    #--------------------Training----------------------\n",
    "    SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "    SVC_clf.fit(X_train,y_train)\n",
    "    #--------------------Evaluation----------------------\n",
    "    y_pred = SVC_clf.predict(X_test)\n",
    "\n",
    "    y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "    y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=['No_pressure_ulcer','pressure_ulcer']))\n",
    "    print(metrics.confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    y_pred_prob2 = y_pred_proba[:,1]\n",
    "    fpr,tpr,thres = roc_curve(y_test,y_pred_prob2)\n",
    "    print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob2))\n",
    "    return sklearn.metrics.roc_auc_score(y_test, y_pred_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline_helper import PipelineHelper\n",
    "X = new_text_total\n",
    "Y = label_total\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', PipelineHelper([\n",
    "        ('count', CountVectorizer(stop_words='english'),\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english'),\n",
    "    ])),\n",
    "    ('classifier', PipelineHelper([\n",
    "        ('Multinomial', MultinomialNB()),\n",
    "        ('Complement', ComplementNB()),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vectorizer__selected_model': pipe.named_steps['vectorizer'].generate({\n",
    "        'count__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "        'count__min_df': [5,10],\n",
    "        'count__max_df': [0.4,0.6,0.8],\n",
    "        'tfidf__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "        'tfidf__min_df':[5,10],\n",
    "        'tfidf__max_df':[0.4,0.6,0.8],\n",
    "    }),\n",
    "    'classifier__selected_model': pipe.named_steps['classifier'].generate({\n",
    "        'Multinomial__alpha': [1.0],\n",
    "        'Complement__alpha': [1.0],\n",
    "    })\n",
    "}\n",
    "grid = GridSearchCV(pipe, params, scoring='accuracy', verbose=1,cv=5,n_jobs=-1)\n",
    "grid.fit(X, Y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vectorizer =TfidfVectorizer(ngram_range=(1,1),min_df =10,stop_words='english',token_pattern=r\"(?u)\\b\\d?[a-z]{2,}\\d?\\b\",max_df = 0.8)\n",
    "Tfidf_vec = Tfidf_vectorizer.fit_transform(new_text_total)\n",
    "print(np.shape(Tfidf_vec))\n",
    "X_train, X_test, y_train, y_test = train_test_split(Tfidf_vec, label_total, test_size=0.2, random_state=41)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['No_pressure_ulcer','ressure_ulcer']))\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn\n",
    "y_pred_prob2 = y_pred_proba[:,1]\n",
    "fpr,tpr,thres = roc_curve(y_test,y_pred_prob2)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob2))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='SVM')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _svm_pipeline_1gram(global_idf):\n",
    "    Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),min_df =5,stop_words='english',max_df = 0.8)\n",
    "    #--------------------Vectorize----------------------\n",
    "    # Use the idf of whole text or only the idf of training dataset\n",
    "    if global_idf:\n",
    "        Tfidf_vectorizer = Tfidf_vectorizer.fit(new_text_total)\n",
    "    else:\n",
    "        Tfidf_vectorizer = Tfidf_vectorizer.fit(new_text_train)\n",
    "    X_train = Tfidf_vectorizer.transform(new_text_train)\n",
    "    y_train = label_train\n",
    "    X_test = Tfidf_vectorizer.transform(new_text_test)\n",
    "    y_test = label_test\n",
    "    print(np.shape(X_train))\n",
    "    #--------------------Training----------------------\n",
    "    SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "    SVC_clf.fit(X_train,y_train)\n",
    "    #--------------------Evaluation----------------------\n",
    "    y_pred = SVC_clf.predict(X_test)\n",
    "\n",
    "    y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "    y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=['No_pressure_ulcer','pressure_ulcer']))\n",
    "    print(metrics.confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    y_pred_prob2 = y_pred_proba[:,1]\n",
    "    fpr,tpr,thres = roc_curve(y_test,y_pred_prob2)\n",
    "    print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob2))\n",
    "    return sklearn.metrics.roc_auc_score(y_test, y_pred_prob2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
