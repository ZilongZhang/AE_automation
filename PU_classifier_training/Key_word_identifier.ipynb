{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'../tools')\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import time\n",
    "import utils\n",
    "import os\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "imp.reload(utils)\n",
    "import pickle\n",
    "text_train = pickle.load(open('../preprocessing/result/pu_ratio2/text_train.pkl','rb'))\n",
    "label_train = pickle.load(open('../preprocessing/result/pu_ratio2/label_train.pkl','rb'))\n",
    "text_test = pickle.load(open('../preprocessing/result/pu_ratio2/text_test.pkl','rb'))\n",
    "label_test = pickle.load(open('../preprocessing/result/pu_ratio2/label_test.pkl','rb'))\n",
    "train_len = len(text_train)\n",
    "print(train_len)\n",
    "text_train.extend(text_test)\n",
    "label_train.extend(label_test)\n",
    "text_total = text_train\n",
    "label_total = label_train\n",
    "new_text_total = utils.back_to_doc(text_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en',disable = [\"parser\", \"ner\"])\n",
    "def lemma(doc):\n",
    "    doc = nlp(doc)\n",
    "    lemmatized_doc = ''\n",
    "    for token in doc:\n",
    "        if not token.lemma_ == '-PRON-':\n",
    "            lemmatized_doc += ' ' + token.lemma_\n",
    "    return lemmatized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5334/5334 [05:33<00:00, 15.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lemmatized_text = []\n",
    "for doc in tqdm(new_text_total):\n",
    "    doc = lemma(doc)\n",
    "    lemmatized_text.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_train = lemmatized_text[:train_len]\n",
    "label_train = label_total[:train_len]\n",
    "new_text_test = lemmatized_text[train_len:]\n",
    "label_test = label_total[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4267\n"
     ]
    }
   ],
   "source": [
    "print(len(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_dir = '../preprocessing/result/pu_ratio2/'\n",
    "pickle.dump(new_text_train,open(des_dir + 'text_train_lemma.pkl','wb'))\n",
    "pickle.dump(new_text_test,open(des_dir + 'text_test_lemma.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you already have lemmatized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '../preprocessing/result/pu_ratio2/'\n",
    "new_text_train = pickle.load(open(src_dir + 'text_train_lemma.pkl','rb'))\n",
    "new_text_test = pickle.load(open(src_dir + 'text_test_lemma.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w return with fever to 102 F. here in the ed be .4 F. Patient conversant , however not sure why be here . be unable to report any problem . during last hospital stay , Mr. be reintubate once for aspir'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_train[0][500:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' returns with fevers to 102 F. Here in the ED he is .4 F. Patient conversant, however not sure why he is here. He is unable to report any problems. During his last hospital stay, Mr. was reintubated o'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_total[0][500:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1,2 gram SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4267, 124451)\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df =5,stop_words='english',max_df = 0.8)\n",
    "X_train = Tfidf_vectorizer.fit_transform(new_text_train)\n",
    "Y_train = label_total[:train_len]\n",
    "X_test = Tfidf_vectorizer.transform(new_text_test)\n",
    "Y_test = label_total[train_len:]\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       No_PU       0.87      0.90      0.89       711\n",
      "          PU       0.79      0.73      0.76       356\n",
      "\n",
      "    accuracy                           0.84      1067\n",
      "   macro avg       0.83      0.82      0.82      1067\n",
      "weighted avg       0.84      0.84      0.84      1067\n",
      "\n",
      "[[642  69]\n",
      " [ 97 259]]\n",
      "0.8152408381927654\n"
     ]
    }
   ],
   "source": [
    "SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf.fit(X_train, Y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_PU','PU']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9240032238183283\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(Y_test, y_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pu_clf_12gram.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(SVC_clf, 'pu_clf_12gram.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf = svm.SVC(,probability=1)\n",
    "SVC_clf.fit(X_train, Y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_PU','PU']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4267, 125847)\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df =5,stop_words='english',max_df = 0.8)\n",
    "X_train = Tfidf_vectorizer.fit_transform(utils.back_to_doc(text_train)[:train_len])\n",
    "Y_train = label_total[:train_len]\n",
    "X_test = Tfidf_vectorizer.transform(utils.back_to_doc(text_test))\n",
    "Y_test = label_total[train_len:]\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       No_PU       0.86      0.91      0.89       711\n",
      "          PU       0.80      0.71      0.75       356\n",
      "\n",
      "    accuracy                           0.84      1067\n",
      "   macro avg       0.83      0.81      0.82      1067\n",
      "weighted avg       0.84      0.84      0.84      1067\n",
      "\n",
      "[[648  63]\n",
      " [103 253]]\n",
      "0.811033281183331\n"
     ]
    }
   ],
   "source": [
    "SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf.fit(X_train, Y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_PU','PU']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4267, 16116)\n"
     ]
    }
   ],
   "source": [
    "Count_vectorizer = CountVectorizer(min_df =5,stop_words='english',max_df = 0.8)\n",
    "X_train = Count_vectorizer.fit_transform(utils.back_to_doc(text_train)[:train_len])\n",
    "Y_train = label_total[:train_len]\n",
    "X_test = Count_vectorizer.transform(utils.back_to_doc(text_test))\n",
    "Y_test = label_total[train_len:]\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       No_PU       0.82      0.91      0.87       711\n",
      "          PU       0.78      0.61      0.69       356\n",
      "\n",
      "    accuracy                           0.81      1067\n",
      "   macro avg       0.80      0.76      0.78      1067\n",
      "weighted avg       0.81      0.81      0.81      1067\n",
      "\n",
      "[[650  61]\n",
      " [138 218]]\n",
      "0.7632824475734445\n"
     ]
    }
   ],
   "source": [
    "SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf.fit(X_train, Y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_PU','PU']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df =5,stop_words='english',max_df = 0.8)\n",
    "X_train = Tfidf_vectorizer.fit_transform(utils.back_to_doc(text_train)[:train_len])\n",
    "Y_train = label_total[:train_len]\n",
    "X_test = Tfidf_vectorizer.transform(utils.back_to_doc(text_test))\n",
    "Y_test = label_total[train_len:]\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'py37_SVC_clf_12gram.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e3fd02a6fbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVC_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'py37_SVC_clf_12gram.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'No_infection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'infection'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'py37_SVC_clf_12gram.joblib'"
     ]
    }
   ],
   "source": [
    "SVC_clf = load('py37_SVC_clf_12gram.joblib')\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_infection','infection']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('svm_y_pred.npy',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2887,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = label_total[:train_len]\n",
    "print(np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No_infection       0.87      0.91      0.89       711\n",
      "   infection       0.79      0.73      0.76       356\n",
      "\n",
      "    accuracy                           0.85      1067\n",
      "   macro avg       0.83      0.82      0.82      1067\n",
      "weighted avg       0.84      0.85      0.84      1067\n",
      "\n",
      "[[644  67]\n",
      " [ 97 259]]\n",
      "0.8166473079536654\n"
     ]
    }
   ],
   "source": [
    "SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf.fit(X_train, Y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_PU','PU']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf.fit(X_train, Y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_PU','PU']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 83475)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC_clf_12gram.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(SVC_clf, 'SVC_clf_12gram.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No_infection       0.85      0.96      0.90       481\n",
      "   infection       0.90      0.65      0.76       241\n",
      "\n",
      "    accuracy                           0.86       722\n",
      "   macro avg       0.87      0.81      0.83       722\n",
      "weighted avg       0.87      0.86      0.85       722\n",
      "\n",
      "[[464  17]\n",
      " [ 84 157]]\n",
      "0.8080546234073206\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train,Y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "y_pred_proba = LR.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_infection','infection']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_clf_12gram.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(LR, 'LR_clf_12gram.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 gram SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2887, 11741)\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),min_df =5,stop_words='english',max_df = 0.8)\n",
    "X_train = Tfidf_vectorizer.fit_transform(new_text_train)\n",
    "Y_train = label_total[:train_len]\n",
    "X_test = Tfidf_vectorizer.transform(new_text_test)\n",
    "Y_test = label_total[train_len:]\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2887,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No_infection       0.88      0.93      0.91       481\n",
      "   infection       0.85      0.76      0.80       241\n",
      "\n",
      "    accuracy                           0.87       722\n",
      "   macro avg       0.87      0.84      0.85       722\n",
      "weighted avg       0.87      0.87      0.87       722\n",
      "\n",
      "[[448  33]\n",
      " [ 59 182]]\n",
      "0.8432898266923163\n"
     ]
    }
   ],
   "source": [
    "SVC_clf_1gram = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf_1gram.fit(X_train,Y_train)\n",
    "y_pred = SVC_clf_1gram.predict(X_test)\n",
    "\n",
    "y_pred_proba = SVC_clf_1gram.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_infection','infection']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC_clf_1gram.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(SVC_clf_1gram, 'SVC_clf_1gram.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No_infection       0.86      0.96      0.91       481\n",
      "   infection       0.91      0.69      0.78       241\n",
      "\n",
      "    accuracy                           0.87       722\n",
      "   macro avg       0.88      0.83      0.85       722\n",
      "weighted avg       0.88      0.87      0.87       722\n",
      "\n",
      "[[464  17]\n",
      " [ 75 166]]\n",
      "0.826726822577445\n"
     ]
    }
   ],
   "source": [
    "LR_1gram = LogisticRegression(max_iter=1000)\n",
    "LR_1gram.fit(X_train,Y_train)\n",
    "y_pred = LR_1gram.predict(X_test)\n",
    "\n",
    "y_pred_proba = LR_1gram.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_infection','infection']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_clf_1gram.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(LR_1gram, 'LR_clf_1gram.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539091962955342\n",
      "['wound', 'cellulitis', 'sternal', 'erythema', 'abscess', 'vancomycin', 'site', 'open', 'collection', 'knee', 'post', 'laparotomy', 'infection', 'antibiotic', 'exploratory', 'incision', 'surgery', 'id', 'trough', 'washout', 'culture', 'keflex', 'hardware', 'bone', 'pressor', 'dress', '14', 'leak', 'ercp', 'rehab', 'whipple', 'hip', 'duodenum', 'linezolid', 'complicate', 'undergo', 'biopsy', 'cholecystectomy', 'fluid', 'vegetation', 'develop', 'continue', 'start', 'osteomyelitis', 'orthopedic', 'debridement', 'dehiscence', 'grow', 'tibia', 'ileostomy', 'colectomy', 'flap', 'drain', 'suppository', 'repair', 'colic', 'line', 'cbd', 'elevate', 'placement', 'inr', 'augmentin', 'pod', 'perforation', 'resection', 'femoral', 'worsen', '12h', '500', '70', 'infectious', 'charcot', 'place', 'prn', 'growth', 'vac', 'anastomosis', 'nafcillin', 'ankle', '53am', 'hemi', 'soln', 'gram', '78', 'midodrine', 'bilateral', 'support', 'goal', 'unasyn', 'cephalexin', 'slowly', 'laparoscopic', 'provider', 'sepsis', 'draw', 'cmo', 'moderate', 'experience', 'ngt', '05']\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(utils)\n",
    "pos_words = utils.show_word_new(Tfidf_vectorizer,SVC_clf_1gram,100,for_pos = True)\n",
    "print(pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6439329484590215\n",
      "['ulcer', 'pancreatitis', 'intact', 'urinary', 'unremarkable', '50', 'initially', 'sided', 'pressure', 'hct', 'baseline', 'hcl', 'hemodialysis', 'negative', 'carcinoma', 'viral', 'avm', 'insufficiency', 'esrd', 'known', 'peg', 'intervention', '40am', 'denie', '20pm', 'obesity', 'father', 'bp', 'mediastinal', 'stool', 'igg', 'mvr', 'ed', 'weakness', 'regimen', 'contrast', 'vessel', 'coronary', 'pericardial', 'severely', 'arterial', 'cefepime', 'center', 'cataract', 'sob', 'rapid', 'paraesophageal', '91', 'pa', '31pm', 'ranitidine', 'dialysis', 'carotid', 'sinus', 'retrocardiac', 'thoracotomy', 'monitoring', 'c6', 'myxoma', 'diverticulitis', 'skull', 'pseudocyst', 'peak', 'cough', 'neuro', 'occlusion', 'nt', 'nasogastric', 'sputum', 'foley', 'release', 'venous', 'trend', 'dysfunction', 'fio2', '48pm', 'glaucoma', 'husband', 'independently', 'concern', 'consistent', 'lactate', 'cocaine', 'mri', 'dilate', 'answer', '68', 'ambulatory', 'minimally', 'breathe', 'tab', 'bilat', 'card', 'trauma', '103', '12pm', 'codeine', 'extraocular', 'health', 'stenting']\n"
     ]
    }
   ],
   "source": [
    "neg_words = utils.show_word_new(Tfidf_vectorizer,SVC_clf_1gram,100,for_pos = False)\n",
    "print(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2316297894203434\n",
      "['uti', 'tract', 'urinary', 'sepsis', 'infection', 'ciprofloxacin', 'diff', 'difficile', 'septic', 'positive', 'cipro', 'treat', 'urine', 'ua', 'klebsiella', 'pseudomonas', 'start', 'culture', 'grow', 'clarithromycin', '500', 'nitrofurantoin', 'nafcillin', 'colitis', 'mod', 'urinalysis', 'vancomycin', 'amoxicillin', 'shock', 'flagyl', 'pneumonia', 'staph', 'pylori', 'expire', 'pressor', 'vanco', 'bactrim', 'levofloxacin', 'organisms', 'bacteria', 'clostridium', '000', 'hypotension', 'metronidazole', 'enterococcus', 'failure', 'sensitive', 'complete', 'ml', 'coagulase', 'levophe', 'wbc', 'ostomy', 'coli', 'place', 'decortication', 'yeast', 'cefpodoxime', 'develop', 'vasopressor', 'eventually', 'daughter', 'sputum', 'q12h', 'placement', 'tracheostomy', 'fall', 'cdiff', 'urosepsis', 'pylorus', 'central', 'hypotensive', 'mssa', 'require', 'zosyn', 'female', 'pneumoniae', 'wheelchair', 'expired', 'spectrum', 'pan', 'mrs', 'picc', 'multiple', 'resuscitate', 'resuscitation', 'die', '125', '02am', 'epi', 'intubate', 'rehabilitation', 'antibiotic', 'pansensitive', 'aneurysm', 'l1', 'id', 'droop', 'scalp', 'neurontin']\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(utils)\n",
    "pos_words = utils.show_word_new(Tfidf_vectorizer,LR_1gram,100,for_pos = True)\n",
    "print(pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('/home/zilong.zhang1/AE_automation/BERT/pretrained_bert_tf/biobert_pretrain_output_all_notes_150000/vocab.txt','r',encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "for line in lines:\n",
    "    token = line.strip()\n",
    "    vocab_dict[token] =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellulitis\n",
      "sternal\n",
      "erythema\n",
      "abscess\n",
      "vancomycin\n",
      "laparotomy\n",
      "antibiotic\n",
      "exploratory\n",
      "incision\n",
      "trough\n",
      "washout\n",
      "keflex\n",
      "pressor\n",
      "ercp\n",
      "rehab\n",
      "whipple\n",
      "duodenum\n",
      "linezolid\n",
      "complicate\n",
      "biopsy\n",
      "cholecystectomy\n",
      "osteomyelitis\n",
      "orthopedic\n",
      "debridement\n",
      "dehiscence\n",
      "tibia\n",
      "ileostomy\n",
      "colectomy\n",
      "suppository\n",
      "colic\n",
      "cbd\n",
      "elevate\n",
      "inr\n",
      "augmentin\n",
      "perforation\n",
      "resection\n",
      "femoral\n",
      "worsen\n",
      "12h\n",
      "charcot\n",
      "prn\n",
      "vac\n",
      "anastomosis\n",
      "nafcillin\n",
      "53am\n",
      "hemi\n",
      "soln\n",
      "midodrine\n",
      "unasyn\n",
      "cephalexin\n",
      "laparoscopic\n",
      "sepsis\n",
      "cmo\n",
      "ngt\n"
     ]
    }
   ],
   "source": [
    "for www in pos_words:\n",
    "    if www not in vocab_dict:\n",
    "        print(www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ulcer\n",
      "pancreatitis\n",
      "urinary\n",
      "unremarkable\n",
      "hct\n",
      "baseline\n",
      "hcl\n",
      "hemodialysis\n",
      "carcinoma\n",
      "avm\n",
      "insufficiency\n",
      "esrd\n",
      "peg\n",
      "40am\n",
      "denie\n",
      "20pm\n",
      "obesity\n",
      "bp\n",
      "mediastinal\n",
      "igg\n",
      "mvr\n",
      "regimen\n",
      "coronary\n",
      "pericardial\n",
      "arterial\n",
      "cefepime\n",
      "cataract\n",
      "paraesophageal\n",
      "pa\n",
      "31pm\n",
      "ranitidine\n",
      "dialysis\n",
      "carotid\n",
      "sinus\n",
      "retrocardiac\n",
      "thoracotomy\n",
      "c6\n",
      "myxoma\n",
      "diverticulitis\n",
      "pseudocyst\n",
      "neuro\n",
      "occlusion\n",
      "nt\n",
      "nasogastric\n",
      "sputum\n",
      "foley\n",
      "venous\n",
      "dysfunction\n",
      "fio2\n",
      "48pm\n",
      "glaucoma\n",
      "lactate\n",
      "mri\n",
      "dilate\n",
      "ambulatory\n",
      "minimally\n",
      "tab\n",
      "bilat\n",
      "12pm\n",
      "codeine\n",
      "extraocular\n",
      "stenting\n"
     ]
    }
   ],
   "source": [
    "for www in neg_words:\n",
    "    if www not in vocab_dict:\n",
    "        print(www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sklearn' from '/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/sklearn/__init__.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.2min\n",
      "exception calling callback for <Future at 0x7f68cb7c0a20 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\", line 340, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\", line 769, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/_parallel_backends.py\", line 551, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/externals/loky/reusable_executor.py\", line 160, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/home/zilong.zhang1/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/externals/loky/process_executor.py\", line 1027, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b76009b44c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     32\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \"\"\"\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 160\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35/lib/python3.5/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "# Grid Search for NB parameters\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline_helper import PipelineHelper\n",
    "X = new_text_total\n",
    "Y = label_total\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', PipelineHelper([\n",
    "        ('count', CountVectorizer(stop_words='english')),\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ])),\n",
    "    ('classifier', PipelineHelper([\n",
    "        ('Multinomial', MultinomialNB()),\n",
    "        ('Complement', ComplementNB()),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vectorizer__selected_model': pipe.named_steps['vectorizer'].generate({\n",
    "        'count__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "        'count__min_df': [5,10],\n",
    "        'count__max_df': [0.4,0.6,0.8],\n",
    "        'tfidf__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "        'tfidf__min_df':[5,10],\n",
    "        'tfidf__max_df':[0.4,0.6,0.8],\n",
    "    }),\n",
    "    'classifier__selected_model': pipe.named_steps['classifier'].generate({\n",
    "        'Multinomial__alpha': [1.0],\n",
    "        'Complement__alpha': [1.0],\n",
    "    })\n",
    "}\n",
    "grid = GridSearchCV(pipe, params, scoring='accuracy', verbose=1,cv=5,n_jobs=-1)\n",
    "grid.fit(X, Y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vectorizer =TfidfVectorizer(ngram_range=(1,1),min_df =10,stop_words='english',token_pattern=r\"(?u)\\b\\d?[a-z]{2,}\\d?\\b\",max_df = 0.8)\n",
    "Tfidf_vec = Tfidf_vectorizer.fit_transform(new_text_total)\n",
    "print(np.shape(Tfidf_vec))\n",
    "X_train, X_test, y_train, y_test = train_test_split(Tfidf_vec, label_total, test_size=0.2, random_state=41)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['No_pressure_ulcer','ressure_ulcer']))\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn\n",
    "y_pred_prob2 = y_pred_proba[:,1]\n",
    "fpr,tpr,thres = roc_curve(y_test,y_pred_prob2)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob2))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='SVM')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _svm_pipeline_1gram(global_idf):\n",
    "    Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),min_df =5,stop_words='english',max_df = 0.8)\n",
    "    #--------------------Vectorize----------------------\n",
    "    # Use the idf of whole text or only the idf of training dataset\n",
    "    if global_idf:\n",
    "        Tfidf_vectorizer = Tfidf_vectorizer.fit(new_text_total)\n",
    "    else:\n",
    "        Tfidf_vectorizer = Tfidf_vectorizer.fit(new_text_train)\n",
    "    X_train = Tfidf_vectorizer.transform(new_text_train)\n",
    "    y_train = label_train\n",
    "    X_test = Tfidf_vectorizer.transform(new_text_test)\n",
    "    y_test = label_test\n",
    "    print(np.shape(X_train))\n",
    "    #--------------------Training----------------------\n",
    "    SVC_clf = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "    SVC_clf.fit(X_train,y_train)\n",
    "    #--------------------Evaluation----------------------\n",
    "    y_pred = SVC_clf.predict(X_test)\n",
    "\n",
    "    y_pred_proba = SVC_clf.predict_proba(X_test)\n",
    "    y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=['No_pressure_ulcer','pressure_ulcer']))\n",
    "    print(metrics.confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    y_pred_prob2 = y_pred_proba[:,1]\n",
    "    fpr,tpr,thres = roc_curve(y_test,y_pred_prob2)\n",
    "    print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob2))\n",
    "    return sklearn.metrics.roc_auc_score(y_test, y_pred_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator,validation_generator,dummy_generator = utils.load_data_new()\n",
    "for aaa in validation_generator:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
