{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'../tools')\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn\n",
    "import time\n",
    "import utils\n",
    "import os\n",
    "from joblib import dump, load\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887\n"
     ]
    }
   ],
   "source": [
    "imp.reload(utils)\n",
    "import pickle\n",
    "text_train,label_train,text_test,label_test = utils.load_raw_data_new()\n",
    "train_len = len(text_train)\n",
    "print(train_len)\n",
    "text_train.extend(text_test)\n",
    "label_train.extend(label_test)\n",
    "text_total = text_train\n",
    "label_total = label_train\n",
    "new_text_total = utils.back_to_doc(text_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '../preprocessing/result/ratio2/'\n",
    "new_text_train = pickle.load(open(src_dir + 'text_train_lemma.pkl','rb'))\n",
    "new_text_test = pickle.load(open(src_dir + 'text_test_lemma.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2887, 11741)\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),min_df =5,stop_words='english',max_df = 0.8)\n",
    "X_train = Tfidf_vectorizer.fit_transform(new_text_train)\n",
    "Y_train = label_total[:train_len]\n",
    "X_test = Tfidf_vectorizer.transform(new_text_test)\n",
    "Y_test = label_total[train_len:]\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No_infection       0.89      0.93      0.91       481\n",
      "   infection       0.85      0.76      0.80       241\n",
      "\n",
      "    accuracy                           0.87       722\n",
      "   macro avg       0.87      0.85      0.85       722\n",
      "weighted avg       0.87      0.87      0.87       722\n",
      "\n",
      "[[448  33]\n",
      " [ 58 183]]\n",
      "0.8453645154889968\n"
     ]
    }
   ],
   "source": [
    "SVC_clf_1gram = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=1)\n",
    "SVC_clf_1gram.fit(X_train,Y_train)\n",
    "y_pred = SVC_clf_1gram.predict(X_test)\n",
    "\n",
    "y_pred_proba = SVC_clf_1gram.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba,axis=-1)\n",
    "\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['No_infection','infection']))\n",
    "print(metrics.confusion_matrix(Y_test,y_pred))\n",
    "print(metrics.roc_auc_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = SVC_clf_1gram.predict_proba(X_test)\n",
    "np.shape(y_pred_proba)\n",
    "y_pred_proba = y_pred_proba[:,1]\n",
    "Y_test  = np.array(Y_test)\n",
    "diff = Y_test - y_pred_proba\n",
    "obivious_wrong = np.where(diff < -0.5)[0]\n",
    "print(len(obivious_wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "obivious_wrong_bert = np.array([ 38,  44,  50,  60,  71, 127, 137, 154, 163, 165, 246, 270, 302,\n",
    "       311, 329, 393, 395, 449, 461, 489, 513, 522, 523, 552, 561, 592,\n",
    "       622, 625, 662, 666, 705, 712])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obivious_wrong_bert = set(obivious_wrong_bert)\n",
    "obivious_wrong = set(obivious_wrong)\n",
    "both_wrong = obivious_wrong.intersection(obivious_wrong_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obivious_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{38,\n",
       " 44,\n",
       " 60,\n",
       " 71,\n",
       " 137,\n",
       " 270,\n",
       " 311,\n",
       " 329,\n",
       " 393,\n",
       " 449,\n",
       " 461,\n",
       " 513,\n",
       " 523,\n",
       " 592,\n",
       " 625,\n",
       " 662,\n",
       " 666,\n",
       " 705}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label accroding to ICD is 0, but model predicted: 0.7212356043702999\n",
      "The label accroding to ICD is 0, but model predicted: 0.7036312632139125\n",
      "The label accroding to ICD is 0, but model predicted: 0.521614449713669\n",
      "The label accroding to ICD is 0, but model predicted: 0.7127888199000468\n",
      "The label accroding to ICD is 0, but model predicted: 0.864576265642625\n",
      "The label accroding to ICD is 0, but model predicted: 0.6552214853689756\n",
      "The label accroding to ICD is 0, but model predicted: 0.5577633759402486\n",
      "The label accroding to ICD is 0, but model predicted: 0.6657360482573027\n",
      "The label accroding to ICD is 0, but model predicted: 0.9555607643441474\n",
      "The label accroding to ICD is 0, but model predicted: 0.70812010553895\n",
      "The label accroding to ICD is 0, but model predicted: 0.5750495120824908\n",
      "The label accroding to ICD is 0, but model predicted: 0.613327488997818\n",
      "The label accroding to ICD is 0, but model predicted: 0.9627544899924041\n",
      "The label accroding to ICD is 0, but model predicted: 0.5077733086855031\n",
      "The label accroding to ICD is 0, but model predicted: 0.831710174474125\n",
      "The label accroding to ICD is 0, but model predicted: 0.6067068958284413\n",
      "The label accroding to ICD is 0, but model predicted: 0.8618284912058349\n",
      "The label accroding to ICD is 0, but model predicted: 0.5459747041251084\n",
      "The label accroding to ICD is 0, but model predicted: 0.6858185432177709\n",
      "The label accroding to ICD is 0, but model predicted: 0.572972822385184\n",
      "The label accroding to ICD is 0, but model predicted: 0.5454014979223415\n",
      "The label accroding to ICD is 0, but model predicted: 0.807750495499571\n",
      "The label accroding to ICD is 0, but model predicted: 0.9798222718474624\n",
      "The label accroding to ICD is 0, but model predicted: 0.6314946642559901\n",
      "The label accroding to ICD is 0, but model predicted: 0.6247452532328033\n",
      "The label accroding to ICD is 0, but model predicted: 0.5071521349702067\n",
      "The label accroding to ICD is 0, but model predicted: 0.5485370596958831\n",
      "The label accroding to ICD is 0, but model predicted: 0.5619452343401401\n",
      "The label accroding to ICD is 0, but model predicted: 0.9148675036573553\n",
      "The label accroding to ICD is 0, but model predicted: 0.8104373450196447\n",
      "The label accroding to ICD is 0, but model predicted: 0.9892455942485737\n",
      "The label accroding to ICD is 0, but model predicted: 0.5131930504611854\n",
      "The label accroding to ICD is 0, but model predicted: 0.6747684899229364\n"
     ]
    }
   ],
   "source": [
    "log = 'The label accroding to ICD is {}, but model predicted: {}'\n",
    "for sample_index in obivious_wrong:\n",
    "    print(log.format(Y_test[sample_index], y_pred_proba[sample_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_review = {38, 44, 60, 71, 137, 270, 311, 329, 393, 449, 461, 513, 523, 592, 625, 662, 666, 705}\n",
    "att_generator = utils.output_att_scores(hpara1,model_word,model_sent,save_dir,data_generator,tokenizer,use_angular=False,narrow=True,epoch=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
